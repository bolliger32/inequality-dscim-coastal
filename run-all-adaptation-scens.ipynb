{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f280d979-ca4a-48f4-a1ce-1d8d9df1d011",
   "metadata": {},
   "source": [
    "# Run pyCIAM on 3 different adaptation scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f530baa-8bdf-4028-b50f-31fd3150d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a73a3893-a755-4b2d-aace-b1caa0d43a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "import dask.config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from distributed import as_completed\n",
    "from pyCIAM.constants import CASE_DICT\n",
    "from pyCIAM.io import check_finished_zarr_workflow\n",
    "from pyCIAM.run import (\n",
    "    _aggregate_results,\n",
    "    _check_completed_fut_batch,\n",
    "    _get_selectors,\n",
    "    execute_pyciam,\n",
    ")\n",
    "from shared import (\n",
    "    AUTHOR,\n",
    "    BIN_MAP_PATH,\n",
    "    CONTACT,\n",
    "    DIR_RAW,\n",
    "    DIR_SCRATCH,\n",
    "    HISTORY,\n",
    "    PATH_OUTPUT,\n",
    "    PATH_OUTPUT_FIXEDADAPT,\n",
    "    PATH_OUTPUT_GLOBALADAPT,\n",
    "    PATH_PARAMS,\n",
    "    PATH_REFA,\n",
    "    PATH_REFA_GLOBALADAPT,\n",
    "    PATH_SLIIDERS,\n",
    "    PATH_SLIIDERS_SEG,\n",
    "    PATH_SLIIDERS_SEG_TMP,\n",
    "    PATH_SLR_INT,\n",
    "    PATHS_SURGE_LOOKUP,\n",
    "    SEG_CHUNKSIZE,\n",
    "    TMPPATH,\n",
    "    TMPPATH_FIXEDADAPT,\n",
    "    TMPPATH_GLOBALADAPT,\n",
    "    start_dask_cluster,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1fec71b-4440-4839-ab01-212a7f1172e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTION = \"pyCIAM outputs using impact-region SLIIDERS database from DSCIM-EPA, modified slightly to update VSL numbers and remove pre-matched SLR site id, which was matched to LocalizeSL SLR data that is no longer used. Outputs are run against a selection of FACTS simulated SLR scenarios associated with AR6. Specific workflows, SSP scenarios, and monte carlo samples are chosen to give a wide range of samples for global SLR in each year up to 2100, covering as much as possible the support of the FaIR+SESL GMSL projections used to generate a coastal SCC as part of DSCIM.\"\n",
    "\n",
    "PATH_SLIIDERS_TMP = DIR_SCRATCH / \"sliiders-tmp.zarr\"\n",
    "\n",
    "PARAMS = pd.read_json(PATH_PARAMS)[\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867be29e-a030-4966-93ff-b2568a566cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_gateway import Gateway\n",
    "\n",
    "gateway = Gateway()\n",
    "gateway.list_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c430ff59-0c25-40e4-a569-af52ad2771f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64202a1c9428452cadb725f464ed2679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client, cluster = start_dask_cluster(\n",
    "    env_items={\n",
    "        \"DASK_DISTRIBUTED__SCHEDULER__ALLOWED_FAILURES\": \"10\",\n",
    "    }\n",
    ")\n",
    "cluster.scale(250)\n",
    "\n",
    "# cluster = gateway.connect(gateway.list_clusters()[0].name)\n",
    "# client = cluster.get_client()\n",
    "\n",
    "# from distributed import Client\n",
    "\n",
    "# client = Client(n_workers=7)\n",
    "# cluster = client.cluster\n",
    "\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe18c74-c40f-4fd7-ba06-0f1e4b839313",
   "metadata": {},
   "source": [
    "## Get filter of scenarios to run (comment out if we are not running full set of scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630643d9-185b-47ce-9c9a-455c8021f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scen_mc_filter = (\n",
    "    xr.open_zarr(str(BIN_MAP_PATH), chunks=None)[[\"scenario\", \"sample\"]]\n",
    "    .to_dataframe()\n",
    "    .set_index([\"scenario\", \"sample\"])\n",
    "    .index.unique()\n",
    ")\n",
    "scen_mc_filter = scen_mc_filter.union(\n",
    "    pd.MultiIndex.from_product(\n",
    "        ([\"ncc_ar6\"], scen_mc_filter.get_level_values(\"sample\").unique()),\n",
    "        names=[\"scenario\", \"sample\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db1eea-aeed-488c-882e-367cf1b9ec91",
   "metadata": {},
   "source": [
    "## Run pyCIAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdf8124a-a853-49fc-a5da-7b7c8d022bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_func(ds):\n",
    "    return (\n",
    "        ds.drop_vars(\"npv\").sel(case=[\"noAdaptation\", \"optimalfixed\"]).sum(\"costtype\")\n",
    "    )\n",
    "\n",
    "\n",
    "common_kwargs = dict(\n",
    "    pyciam_seg_chunksize=SEG_CHUNKSIZE,\n",
    "    surge_input_paths=PATHS_SURGE_LOOKUP,\n",
    "    dask_client_func=lambda: client,\n",
    "    remove_tmpfile=False,\n",
    "    seg_var=\"seg_ir\",\n",
    "    adm_var=\"impact_region\",\n",
    "    mc_dim=\"sample\",\n",
    "    quantiles=None,\n",
    "    no_surge_check=True,\n",
    "    other_chunksizes={\"ssp\": 1, \"iam\": 1, \"scen_mc\": 1000},\n",
    "    extra_attrs={\n",
    "        \"author\": AUTHOR,\n",
    "        \"contact\": CONTACT,\n",
    "        \"description\": DESCRIPTION,\n",
    "        \"history\": HISTORY,\n",
    "    },\n",
    "    scen_mc_filter=scen_mc_filter,\n",
    "    postprocess_func=postprocess_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05c66f-6f7b-4a97-93bc-b101dba9b592",
   "metadata": {},
   "source": [
    "### Run normal pyCIAM (full-adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d6818e-eca6-4062-b67a-9816e15b4df2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ESL impacts lookup table if it does not exist...\n",
      "Baseline adaptation RPs already calculated...\n",
      "Queueing jobs to calculate costs for all adaptation scenarios...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.14/site-packages/xarray/structure/chunks.py:180: PerformanceWarning: Increasing number of chunks by factor of 32\n",
      "  _, chunked_data = chunkmanager.unify_chunks(*unify_chunks_args)\n"
     ]
    }
   ],
   "source": [
    "execute_pyciam(\n",
    "    PATH_PARAMS,\n",
    "    PATH_SLIIDERS,\n",
    "    PATH_SLR_INT,\n",
    "    \"ar6\",\n",
    "    PATH_REFA,\n",
    "    econ_input_path_seg=PATH_SLIIDERS_SEG,\n",
    "    output_path=PATH_OUTPUT,\n",
    "    tmp_output_path=TMPPATH,\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec87814-fa68-47fa-9a65-5f14c3a0d32b",
   "metadata": {},
   "source": [
    "### Run fixed adaptation\n",
    "\n",
    "In this run, we hold rho (resilience to storm impacts) fixed at 2000-2014 mean levels. We do **NOT** regenerate \"refA\", which defines present-day adaptation levels by running pyCIAM under a no-climate-change scenario and picking the optimal adaptation height. In other words, we are using the time-varying rho to define refA but then fixing rho at 2000 levels for the actual model run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "000cd886-852c-4fc0-a0dd-a095ac4acb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = PARAMS.loc[\"dr\"]\n",
    "npv_start = PARAMS.loc[\"npv_start\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e7502-d904-496f-a652-7347b82adbf8",
   "metadata": {},
   "source": [
    "Create template zarr for new output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c39acd-2f0c-486b-99f4-d5bd15ed5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = (\n",
    "#     xr.open_zarr(str(TMPPATH))\n",
    "#     .sel(case=\"noAdaptation\", costtype=\"stormPopulation\", drop=True)\n",
    "#     .drop_encoding()\n",
    "# )\n",
    "# template[[\"costs\", \"npv\"]] = template[[\"costs\", \"npv\"]].expand_dims(\n",
    "#     case=[\"noAdaptation\", \"optimalfixed\"]\n",
    "# )\n",
    "\n",
    "# for dv in template.data_vars:\n",
    "#     template[dv] = create_template_dataarray(\n",
    "#         template[dv].dims,\n",
    "#         dict(template[dv].coords),\n",
    "#         {k: v[0] for k, v in template[dv].chunksizes.items()},\n",
    "#         dtype=\"float32\" if dv != \"optimal_case\" else \"uint8\",\n",
    "#         name=dv,\n",
    "#     )\n",
    "\n",
    "# template.to_zarr(str(TMPPATH_FIXEDADAPT), mode=\"w\", compute=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45329fae-cb5b-4bd7-bf37-6a2d3afdd5f1",
   "metadata": {},
   "source": [
    "Run batched jobs to take old output, adjust storm damages with new rho, recalculate NPV, recalculate optimal case, and save to new store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a37677-4ac1-4c85-84e4-8ba32cf59ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_case_new_rho(selectors, eps=1):\n",
    "    # use last fpath to check if this task has already been run\n",
    "    if check_finished_zarr_workflow(\n",
    "        finalstore=TMPPATH_FIXEDADAPT,\n",
    "        varname=\"costs\",\n",
    "        final_selector=selectors,\n",
    "    ):\n",
    "        return None\n",
    "\n",
    "    with xr.open_zarr(str(PATH_SLIIDERS), chunks=None) as ds:\n",
    "        all_segs = ds.seg.load()\n",
    "        all_seg_vars = ds[\"seg_ir\"].load()\n",
    "\n",
    "        segadm_seg_map = all_segs.sel(seg_ir=selectors[\"seg_ir\"])\n",
    "        all_seg_adms = all_seg_vars.isel(\n",
    "            seg_ir=all_segs.isin(np.unique(segadm_seg_map))\n",
    "        )\n",
    "\n",
    "        rho = (\n",
    "            ds.rho.sel(\n",
    "                country=ds.seg_country,\n",
    "                **{\n",
    "                    k: v for k, v in selectors.items() if k not in [\"seg_ir\", \"scen_mc\"]\n",
    "                },\n",
    "            )\n",
    "            .sel(seg_ir=all_seg_adms.values)\n",
    "            .load()\n",
    "            .drop_vars(\"country\")\n",
    "        )\n",
    "\n",
    "    rho_ratio = (1 - rho.sel(year=slice(2000, 2014)).mean(\"year\")) / (1 - rho)\n",
    "    dfact = (1 / (1 + dr)) ** (xr.open_zarr(str(TMPPATH), chunks=None).year - npv_start)\n",
    "\n",
    "    # use single threaded dask over numpy b/c it keeps memory footprint down for irs\n",
    "    # that require loading a lot of seg-irs\n",
    "    npv_delta = (\n",
    "        (\n",
    "            (\n",
    "                xr.open_zarr(str(TMPPATH))\n",
    "                .costs.sel(\n",
    "                    seg_ir=all_seg_adms.values,\n",
    "                    costtype=[\"stormPopulation\", \"stormCapital\"],\n",
    "                    **{k: v for k, v in selectors.items() if k != \"seg_ir\"},\n",
    "                )\n",
    "                .drop_sel(case=\"optimalfixed\")\n",
    "                .sum(\"costtype\")\n",
    "            )\n",
    "            * (rho_ratio - 1)\n",
    "        )\n",
    "        * dfact\n",
    "    ).sum(\"year\")\n",
    "    with dask.config.set(scheduler=\"single-threaded\"):\n",
    "        npv_delta = npv_delta.load()\n",
    "\n",
    "    opt_case = (\n",
    "        (\n",
    "            (\n",
    "                xr.open_zarr(str(TMPPATH), chunks=None)\n",
    "                .npv.sel(\n",
    "                    seg_ir=all_seg_adms.values,\n",
    "                    **{k: v for k, v in selectors.items() if k != \"seg_ir\"},\n",
    "                )\n",
    "                .drop_sel(case=\"optimalfixed\")\n",
    "            )\n",
    "            + npv_delta\n",
    "        )\n",
    "        .groupby(all_seg_adms.seg)\n",
    "        .sum()\n",
    "    )\n",
    "\n",
    "    # in case of a tie, we don't want floating point precision noise to determine the\n",
    "    # choice so we artificially shave 1 dollar off of the noAdaptation npv\n",
    "    opt_case = opt_case.where(opt_case.case != \"noAdaptation\", opt_case - eps).idxmin(\n",
    "        \"case\"\n",
    "    )\n",
    "\n",
    "    opt_case_ser = opt_case.to_series()\n",
    "    opt_val = (\n",
    "        pd.Series(\n",
    "            pd.Series(CASE_DICT).loc[opt_case_ser].values,\n",
    "            index=opt_case_ser.index,\n",
    "        )\n",
    "        .to_xarray()\n",
    "        .astype(\"uint8\")\n",
    "        .sel(seg=segadm_seg_map)\n",
    "    )\n",
    "\n",
    "    # get opt_case back into seg-region dimension\n",
    "    opt_case = opt_case.sel(seg=segadm_seg_map)\n",
    "\n",
    "    out = (\n",
    "        xr.open_zarr(str(TMPPATH), chunks=None)[[\"costs\", \"npv\"]]\n",
    "        .sel(selectors)\n",
    "        .drop_sel(case=\"optimalfixed\")\n",
    "    )\n",
    "    out[\"costs\"] = out.costs.where(\n",
    "        ~out.costtype.isin([\"stormPopulation\", \"stormCapital\"]),\n",
    "        out.costs * rho_ratio.sel(seg_ir=selectors[\"seg_ir\"]),\n",
    "    ).sum(\"costtype\")\n",
    "    out[\"npv\"] += npv_delta.sel(seg_ir=selectors[\"seg_ir\"])\n",
    "\n",
    "    out = out.drop_vars(\"costtype\")\n",
    "\n",
    "    noadapt = out.sel(case=[\"noAdaptation\"])\n",
    "    out = out.sel(case=opt_case).drop_vars(\"case\").expand_dims(case=[\"optimalfixed\"])\n",
    "    out = xr.concat((noadapt, out), dim=\"case\")\n",
    "    out[\"optimal_case\"] = opt_val\n",
    "    out.reset_coords(drop=True).to_zarr(str(TMPPATH_FIXEDADAPT), region=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0698c5ed-2001-4a09-95d1-e774c91fc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_groups, ix_groups = _get_selectors(\n",
    "    xr.open_zarr(str(PATH_SLIIDERS), chunks=None),\n",
    "    \"seg_ir\",\n",
    "    SEG_CHUNKSIZE,\n",
    "    common_kwargs[\"other_chunksizes\"],\n",
    "    xr.open_zarr(str(TMPPATH_FIXEDADAPT), chunks=None),\n",
    "    10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f9c3513-2b51-47bd-823a-63782fb90f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing group 1 / 178\n",
      "computing group 2 / 178\n",
      "computing group 3 / 178\n",
      "computing group 4 / 178\n",
      "computing group 5 / 178\n",
      "computing group 6 / 178\n",
      "computing group 7 / 178\n",
      "computing group 8 / 178\n",
      "computing group 9 / 178\n",
      "computing group 10 / 178\n",
      "computing group 11 / 178\n",
      "computing group 12 / 178\n",
      "computing group 13 / 178\n",
      "computing group 14 / 178\n",
      "computing group 15 / 178\n",
      "computing group 16 / 178\n",
      "computing group 17 / 178\n",
      "computing group 18 / 178\n",
      "computing group 19 / 178\n",
      "computing group 20 / 178\n",
      "computing group 21 / 178\n",
      "computing group 22 / 178\n",
      "computing group 23 / 178\n",
      "computing group 24 / 178\n",
      "computing group 25 / 178\n",
      "computing group 26 / 178\n",
      "computing group 27 / 178\n",
      "computing group 28 / 178\n",
      "computing group 29 / 178\n",
      "computing group 30 / 178\n",
      "computing group 31 / 178\n",
      "computing group 32 / 178\n",
      "computing group 33 / 178\n",
      "computing group 34 / 178\n",
      "computing group 35 / 178\n",
      "computing group 36 / 178\n",
      "computing group 37 / 178\n",
      "computing group 38 / 178\n",
      "computing group 39 / 178\n",
      "computing group 40 / 178\n",
      "computing group 41 / 178\n",
      "computing group 42 / 178\n",
      "computing group 43 / 178\n",
      "computing group 44 / 178\n",
      "computing group 45 / 178\n",
      "computing group 46 / 178\n",
      "computing group 47 / 178\n",
      "computing group 48 / 178\n",
      "computing group 49 / 178\n",
      "computing group 50 / 178\n",
      "computing group 51 / 178\n",
      "computing group 52 / 178\n",
      "computing group 53 / 178\n",
      "computing group 54 / 178\n",
      "computing group 55 / 178\n",
      "computing group 56 / 178\n",
      "computing group 57 / 178\n",
      "computing group 58 / 178\n",
      "computing group 59 / 178\n",
      "computing group 60 / 178\n",
      "computing group 61 / 178\n",
      "computing group 62 / 178\n",
      "computing group 63 / 178\n",
      "computing group 64 / 178\n",
      "computing group 65 / 178\n",
      "computing group 66 / 178\n",
      "computing group 67 / 178\n",
      "computing group 68 / 178\n",
      "computing group 69 / 178\n",
      "computing group 70 / 178\n",
      "computing group 71 / 178\n",
      "computing group 72 / 178\n",
      "computing group 73 / 178\n",
      "computing group 74 / 178\n",
      "computing group 75 / 178\n",
      "computing group 76 / 178\n",
      "computing group 77 / 178\n",
      "computing group 78 / 178\n",
      "computing group 79 / 178\n",
      "computing group 80 / 178\n",
      "computing group 81 / 178\n",
      "computing group 82 / 178\n",
      "computing group 83 / 178\n",
      "computing group 84 / 178\n",
      "computing group 85 / 178\n",
      "computing group 86 / 178\n",
      "computing group 87 / 178\n",
      "computing group 88 / 178\n",
      "computing group 89 / 178\n",
      "computing group 90 / 178\n",
      "computing group 91 / 178\n",
      "computing group 92 / 178\n",
      "computing group 93 / 178\n",
      "computing group 94 / 178\n",
      "computing group 95 / 178\n",
      "computing group 96 / 178\n",
      "computing group 97 / 178\n",
      "computing group 98 / 178\n",
      "computing group 99 / 178\n",
      "computing group 100 / 178\n",
      "computing group 101 / 178\n",
      "computing group 102 / 178\n",
      "computing group 103 / 178\n",
      "computing group 104 / 178\n",
      "computing group 105 / 178\n",
      "computing group 106 / 178\n",
      "computing group 107 / 178\n",
      "computing group 108 / 178\n",
      "computing group 109 / 178\n",
      "computing group 110 / 178\n",
      "computing group 111 / 178\n",
      "computing group 112 / 178\n",
      "computing group 113 / 178\n",
      "computing group 114 / 178\n",
      "computing group 115 / 178\n",
      "computing group 116 / 178\n",
      "computing group 117 / 178\n",
      "computing group 118 / 178\n",
      "computing group 119 / 178\n",
      "computing group 120 / 178\n",
      "computing group 121 / 178\n",
      "computing group 122 / 178\n",
      "computing group 123 / 178\n",
      "computing group 124 / 178\n",
      "computing group 125 / 178\n",
      "computing group 126 / 178\n",
      "computing group 127 / 178\n",
      "computing group 128 / 178\n",
      "computing group 129 / 178\n",
      "computing group 130 / 178\n",
      "computing group 131 / 178\n",
      "computing group 132 / 178\n",
      "computing group 133 / 178\n",
      "computing group 134 / 178\n",
      "computing group 135 / 178\n",
      "computing group 136 / 178\n",
      "computing group 137 / 178\n",
      "computing group 138 / 178\n",
      "computing group 139 / 178\n",
      "computing group 140 / 178\n",
      "computing group 141 / 178\n",
      "computing group 142 / 178\n",
      "computing group 143 / 178\n",
      "computing group 144 / 178\n",
      "computing group 145 / 178\n",
      "computing group 146 / 178\n",
      "computing group 147 / 178\n",
      "computing group 148 / 178\n",
      "computing group 149 / 178\n",
      "computing group 150 / 178\n",
      "computing group 151 / 178\n",
      "computing group 152 / 178\n",
      "computing group 153 / 178\n",
      "computing group 154 / 178\n",
      "computing group 155 / 178\n",
      "computing group 156 / 178\n",
      "computing group 157 / 178\n",
      "computing group 158 / 178\n",
      "computing group 159 / 178\n",
      "computing group 160 / 178\n",
      "computing group 161 / 178\n",
      "computing group 162 / 178\n",
      "computing group 163 / 178\n",
      "computing group 164 / 178\n",
      "computing group 165 / 178\n",
      "computing group 166 / 178\n",
      "computing group 167 / 178\n",
      "computing group 168 / 178\n",
      "computing group 169 / 178\n",
      "computing group 170 / 178\n",
      "computing group 171 / 178\n",
      "computing group 172 / 178\n",
      "computing group 173 / 178\n",
      "computing group 174 / 178\n",
      "computing group 175 / 178\n",
      "computing group 176 / 178\n",
      "computing group 177 / 178\n",
      "computing group 178 / 178\n"
     ]
    }
   ],
   "source": [
    "ciam_futs = None\n",
    "n_selector_groups = len(selector_groups)\n",
    "for sx, s in enumerate(selector_groups):\n",
    "    final_batch = (sx + 1) == n_selector_groups\n",
    "    print(f\"computing group {sx + 1} / {n_selector_groups}\")\n",
    "\n",
    "    this_futs = pd.Series(\n",
    "        s,\n",
    "        index=client.map(\n",
    "            optimize_case_new_rho,\n",
    "            s,\n",
    "        ),\n",
    "    )\n",
    "    if ciam_futs is None:\n",
    "        ciam_futs = this_futs\n",
    "    else:\n",
    "        ciam_futs = pd.concat((ciam_futs, this_futs))\n",
    "    del this_futs\n",
    "\n",
    "    for batch in as_completed(ciam_futs.index.tolist()).batches():\n",
    "        ciam_futs = _check_completed_fut_batch(\n",
    "            batch, ciam_futs, client, optimize_case_new_rho\n",
    "        )\n",
    "        del batch\n",
    "        if ((not final_batch) and len(ciam_futs) < (1000)) or (\n",
    "            final_batch and (not len(ciam_futs))\n",
    "        ):\n",
    "            break\n",
    "        sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "264352c3-ff3b-4e69-a448-f07aa51065fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_npv(ds):\n",
    "    return ds.drop_vars(\"npv\")\n",
    "\n",
    "\n",
    "_aggregate_results(\n",
    "    TMPPATH_FIXEDADAPT,\n",
    "    PATH_OUTPUT_FIXEDADAPT,\n",
    "    PATH_SLIIDERS,\n",
    "    \"seg_ir\",\n",
    "    \"impact_region\",\n",
    "    \"sample\",\n",
    "    client,\n",
    "    scen_mc_filter=scen_mc_filter,\n",
    "    postprocess_func=_drop_npv,\n",
    "    overwrite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "933b8e2f-e8a5-4cbe-b826-1f18ccd64214",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert xr.open_zarr(str(PATH_OUTPUT_FIXEDADAPT)).costs.notnull().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6479e4-114d-4d9a-8e5c-38844bf17d5e",
   "metadata": {},
   "source": [
    "### Run with global average rho\n",
    "\n",
    "First we create a new version of SLIIDERS that contains the population-weighted global average resilience factor ($\\rho$), by country. For the population weighting, we use the 2010 population estimates from the SSPs, previously downscaled to impact regions and now aggregated up to countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35ed4140-7743-4c1f-bc0b-f8d7da776984",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = (\n",
    "    xr.open_zarr(str(DIR_RAW / \"integration-econ-bc39.zarr\"), chunks=None)\n",
    "    .sel(ssp=\"SSP2\", model=\"IIASA GDP\", year=2010, drop=True)[\"pop\"]\n",
    "    .load()\n",
    ")\n",
    "country_pops = (\n",
    "    pop.groupby(pop.region.astype(str).str.split(\"tmp\", sep=\".\").isel(tmp=0))\n",
    "    .sum()\n",
    "    .rename(region=\"country\")\n",
    ")\n",
    "\n",
    "# fix typo in some versions of GADM\n",
    "country_pops[\"country\"] = country_pops.country.str.replace(\"SMX\", \"SXM\")\n",
    "\n",
    "sliiders = xr.open_zarr(str(PATH_SLIIDERS))\n",
    "sliiders[\"rho\"] = (\n",
    "    sliiders.rho.sel(year=slice(2000, 2014))\n",
    "    .mean(\"year\")\n",
    "    .weighted(country_pops.sel(country=sliiders.country.values))\n",
    "    .mean(\"country\")\n",
    "    .expand_dims(country=sliiders.country, year=sliiders.year)\n",
    ")\n",
    "\n",
    "sliiders.to_zarr(str(PATH_SLIIDERS_TMP), mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d99e97-10b6-4397-9097-00afc0dd9d1a",
   "metadata": {},
   "source": [
    "Now, we rerun pyCIAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80533b9-ce99-48b5-9f43-33f5991dd5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ESL impacts lookup table if it does not exist...\n",
      "Baseline adaptation RPs already calculated...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.14/site-packages/zarr/api/asynchronous.py:247: ZarrUserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "execute_pyciam(\n",
    "    PATH_PARAMS,\n",
    "    PATH_SLIIDERS_TMP,\n",
    "    PATH_SLR_INT,\n",
    "    \"ar6\",\n",
    "    PATH_REFA_GLOBALADAPT,\n",
    "    econ_input_path_seg=PATH_SLIIDERS_SEG_TMP,\n",
    "    output_path=PATH_OUTPUT_GLOBALADAPT,\n",
    "    tmp_output_path=TMPPATH_GLOBALADAPT,\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d49480-830d-4d4a-9140-0ae00079d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close(), client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00fb9d1f7611447d811f4a3d8cdfcf5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_b64a991b4dbc45f2a63d902e605f9a59",
        "IPY_MODEL_d73b99ffa6974d919fb77a6436838abc"
       ],
       "layout": "IPY_MODEL_97ec0ce2d8574e3eb2eeb1874100f28d"
      }
     },
     "06f11470bfb044cc9b2cb148440c1703": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "0c83c699675546bd83ba4c0c7669da84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "191aeb348d6648fdabb6758f1f40e953": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "IntTextModel",
      "state": {
       "description": "Maximum",
       "layout": "IPY_MODEL_465240fab71341bd95aa40de55ba5517",
       "step": 1,
       "style": "IPY_MODEL_3baa4e7eb2e44e40acb183fe30559469"
      }
     },
     "237614acfd35487f929afdca5e07efa5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2dffb87f70fb42449cf45eb79b1459b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2fd8d328829f4347a46eb078fe9c6de5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "30fab73f712b4f3aa23e10a0b947bbb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2dffb87f70fb42449cf45eb79b1459b5",
       "style": "IPY_MODEL_0c83c699675546bd83ba4c0c7669da84",
       "value": "<p><b>Name: </b>jhub.728ab0bbb7434ec89a2dbf8f417fab30</p>"
      }
     },
     "32ac3842c8354221a7f4b2f4b1a028e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "min_width": "500px"
      }
     },
     "35f2271e03d64df68678438d88a03f4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "388eeb49a13a4b1496287f0fbc6ce442": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "AccordionModel",
      "state": {
       "children": [
        "IPY_MODEL_00fb9d1f7611447d811f4a3d8cdfcf5c",
        "IPY_MODEL_f9893c29176c49009d5cd31d10558731"
       ],
       "layout": "IPY_MODEL_32ac3842c8354221a7f4b2f4b1a028e4",
       "titles": [
        "Manual Scaling",
        "Adaptive Scaling"
       ]
      }
     },
     "3baa4e7eb2e44e40acb183fe30559469": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3fc4ae4a420c414f86544c76e2cce030": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Adapt",
       "layout": "IPY_MODEL_465240fab71341bd95aa40de55ba5517",
       "style": "IPY_MODEL_e83a64d2f0ef4b5ca0cb42a4d0822aea",
       "tooltip": null
      }
     },
     "465240fab71341bd95aa40de55ba5517": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "150px"
      }
     },
     "550d0ef77b8f4f4eae767bac07795980": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "min_width": "150px"
      }
     },
     "61435b308a45440b9179bfa73dfc6d60": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "64202a1c9428452cadb725f464ed2679": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e349eef80607493abf27f9439a64fb44",
        "IPY_MODEL_7f7a10003ec24fa5bdf6e32828f82f3d",
        "IPY_MODEL_30fab73f712b4f3aa23e10a0b947bbb5",
        "IPY_MODEL_902a4932152e4aaf9b81a25ac7c4c36c"
       ],
       "layout": "IPY_MODEL_a6ae5e47b8b14a819ac66ebd37819915"
      }
     },
     "6a4f662afe0b4ab5810bace84badc61b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "766daf454308409f93e77c271174086d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7f7a10003ec24fa5bdf6e32828f82f3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a9bd52adf6c242f8a57017a70118d933",
        "IPY_MODEL_388eeb49a13a4b1496287f0fbc6ce442"
       ],
       "layout": "IPY_MODEL_ad0fd96fee774b5d8045a90eb3914398"
      }
     },
     "902a4932152e4aaf9b81a25ac7c4c36c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_61435b308a45440b9179bfa73dfc6d60",
       "style": "IPY_MODEL_6a4f662afe0b4ab5810bace84badc61b",
       "value": "<p><b>Dashboard: </b><a href=\"/services/dask-gateway/clusters/jhub.728ab0bbb7434ec89a2dbf8f417fab30/status\" target=\"_blank\">/services/dask-gateway/clusters/jhub.728ab0bbb7434ec89a2dbf8f417fab30/status</a></p>\n"
      }
     },
     "97ec0ce2d8574e3eb2eeb1874100f28d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a6ae5e47b8b14a819ac66ebd37819915": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a9bd52adf6c242f8a57017a70118d933": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_550d0ef77b8f4f4eae767bac07795980",
       "style": "IPY_MODEL_e83abd0921504487b30c1250264c820f",
       "value": "\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table style=\"text-align: right;\">\n    <tr><th>Workers</th> <td>233</td></tr>\n    <tr><th>Threads</th> <td>233</td></tr>\n    <tr><th>Memory</th> <td>1.42 TiB</td></tr>\n</table>\n</div>\n"
      }
     },
     "ad0fd96fee774b5d8045a90eb3914398": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b64a991b4dbc45f2a63d902e605f9a59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "IntTextModel",
      "state": {
       "description": "Workers",
       "layout": "IPY_MODEL_465240fab71341bd95aa40de55ba5517",
       "step": 1,
       "style": "IPY_MODEL_237614acfd35487f929afdca5e07efa5"
      }
     },
     "cbb18098d5ea4e97bc6592cdf103d6d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "IntTextModel",
      "state": {
       "description": "Minimum",
       "layout": "IPY_MODEL_465240fab71341bd95aa40de55ba5517",
       "step": 1,
       "style": "IPY_MODEL_766daf454308409f93e77c271174086d"
      }
     },
     "d73b99ffa6974d919fb77a6436838abc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Scale",
       "layout": "IPY_MODEL_465240fab71341bd95aa40de55ba5517",
       "style": "IPY_MODEL_06f11470bfb044cc9b2cb148440c1703",
       "tooltip": null
      }
     },
     "e349eef80607493abf27f9439a64fb44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_35f2271e03d64df68678438d88a03f4c",
       "style": "IPY_MODEL_2fd8d328829f4347a46eb078fe9c6de5",
       "value": "<h2>GatewayCluster</h2>"
      }
     },
     "e83a64d2f0ef4b5ca0cb42a4d0822aea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "e83abd0921504487b30c1250264c820f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e9437478ceb64ccdb25bbd8b523c4d96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f9893c29176c49009d5cd31d10558731": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cbb18098d5ea4e97bc6592cdf103d6d2",
        "IPY_MODEL_191aeb348d6648fdabb6758f1f40e953",
        "IPY_MODEL_3fc4ae4a420c414f86544c76e2cce030"
       ],
       "layout": "IPY_MODEL_e9437478ceb64ccdb25bbd8b523c4d96"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
